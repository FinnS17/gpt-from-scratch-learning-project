{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "366942f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.gutenberg.org/cache/epub/2230/pg2230.txt\"\n",
    "# text = requests.get(url).text\n",
    "# with open(\"input_llm2.txt\", \"w\") as f:\n",
    "#     f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0b6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207061"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = open(\"../data/input_llm.txt\", \"r\").read()\n",
    "print(len(text1))\n",
    "text2 = open(\"../data/input_llm2.txt\", \"r\").read()\n",
    "print(len(text2))\n",
    "text = text1 + text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b70bbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536565"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22918d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35352b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d212b",
   "metadata": {},
   "source": [
    "### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f15197ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {s: i for i, s in enumerate(chars)}\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c82e4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "703234de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7,  7,  7,  0,  0,  0,  0,  0, 30, 51, 71, 69, 70, 22,  0, 28, 55, 68,\n",
       "         1, 44, 68, 51, 57, 82, 54, 59, 55,  1, 55, 68, 69, 70, 55, 68,  1, 44,\n",
       "        55, 59, 62,  0,  0, 52, 75,  1, 34, 65, 58, 51, 64, 64,  1, 47, 65, 62,\n",
       "        56, 57, 51, 64, 57,  1, 72, 65, 64,  1, 31, 65, 55, 70, 58, 55,  0,  0,\n",
       "         0, 27, 65, 64, 70, 55, 64, 70, 69,  0,  0,  1, 50, 71, 55, 59, 57, 64,\n",
       "        71, 64, 57,  0,  1, 46, 65, 68, 69, 66])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918160c3",
   "metadata": {},
   "source": [
    "### splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be88c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04acb0e7",
   "metadata": {},
   "source": [
    "### data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3183d592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7,  7,  7,  0,  0,  0,  0,  0, 30])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size +1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([7]), output is 7\n",
      "when input is tensor([7, 7]), output is 7\n",
      "when input is tensor([7, 7, 7]), output is 0\n",
      "when input is tensor([7, 7, 7, 0]), output is 0\n",
      "when input is tensor([7, 7, 7, 0, 0]), output is 0\n",
      "when input is tensor([7, 7, 7, 0, 0, 0]), output is 0\n",
      "when input is tensor([7, 7, 7, 0, 0, 0, 0]), output is 0\n",
      "when input is tensor([7, 7, 7, 0, 0, 0, 0, 0]), output is 30\n"
     ]
    }
   ],
   "source": [
    "#for leraning\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1] #first eleemtn - indexing is exlucisve\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context}, output is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9c6ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real implemenation\n",
    "batch_size = 4 #how many batches in paralel\n",
    "block_size = 8 #context length for prediction\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "Xb, Yb = get_batch(\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d73031ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29, 36, 29, 43, 10,  0, 28, 51],\n",
      "        [68, 54, 55, 10,  6,  0,  0, 28],\n",
      "        [ 1, 76, 51, 68, 70, 55, 64,  1],\n",
      "        [ 1, 63, 59, 68,  1, 54, 71, 68]])\n",
      "tensor([[36, 29, 43, 10,  0, 28, 51,  1],\n",
      "        [54, 55, 10,  6,  0,  0, 28, 33],\n",
      "        [76, 51, 68, 70, 55, 64,  1, 34],\n",
      "        [63, 59, 68,  1, 54, 71, 68, 53]])\n"
     ]
    }
   ],
   "source": [
    "print(Xb)\n",
    "print(Yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f03f9faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: tensor([29]) -> label: 36\n",
      "context: tensor([29, 36]) -> label: 29\n",
      "context: tensor([29, 36, 29]) -> label: 43\n",
      "context: tensor([29, 36, 29, 43]) -> label: 10\n",
      "context: tensor([29, 36, 29, 43, 10]) -> label: 0\n",
      "context: tensor([29, 36, 29, 43, 10,  0]) -> label: 28\n",
      "context: tensor([29, 36, 29, 43, 10,  0, 28]) -> label: 51\n",
      "context: tensor([29, 36, 29, 43, 10,  0, 28, 51]) -> label: 1\n",
      "context: tensor([68]) -> label: 54\n",
      "context: tensor([68, 54]) -> label: 55\n",
      "context: tensor([68, 54, 55]) -> label: 10\n",
      "context: tensor([68, 54, 55, 10]) -> label: 6\n",
      "context: tensor([68, 54, 55, 10,  6]) -> label: 0\n",
      "context: tensor([68, 54, 55, 10,  6,  0]) -> label: 0\n",
      "context: tensor([68, 54, 55, 10,  6,  0,  0]) -> label: 28\n",
      "context: tensor([68, 54, 55, 10,  6,  0,  0, 28]) -> label: 33\n",
      "context: tensor([1]) -> label: 76\n",
      "context: tensor([ 1, 76]) -> label: 51\n",
      "context: tensor([ 1, 76, 51]) -> label: 68\n",
      "context: tensor([ 1, 76, 51, 68]) -> label: 70\n",
      "context: tensor([ 1, 76, 51, 68, 70]) -> label: 55\n",
      "context: tensor([ 1, 76, 51, 68, 70, 55]) -> label: 64\n",
      "context: tensor([ 1, 76, 51, 68, 70, 55, 64]) -> label: 1\n",
      "context: tensor([ 1, 76, 51, 68, 70, 55, 64,  1]) -> label: 34\n",
      "context: tensor([1]) -> label: 63\n",
      "context: tensor([ 1, 63]) -> label: 59\n",
      "context: tensor([ 1, 63, 59]) -> label: 68\n",
      "context: tensor([ 1, 63, 59, 68]) -> label: 1\n",
      "context: tensor([ 1, 63, 59, 68,  1]) -> label: 54\n",
      "context: tensor([ 1, 63, 59, 68,  1, 54]) -> label: 71\n",
      "context: tensor([ 1, 63, 59, 68,  1, 54, 71]) -> label: 68\n",
      "context: tensor([ 1, 63, 59, 68,  1, 54, 71, 68]) -> label: 53\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = Xb[b, :t+1]\n",
    "        label = Yb[b, t]\n",
    "        print(f\"context: {context} -> label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d266c",
   "metadata": {},
   "source": [
    "### feed Xb data into bigramm language modell -> sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets= None):\n",
    "\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) #due to problems with pytroch dimensions, just squeeze batches into one\n",
    "            targets = targets.view(B*T) #same here\n",
    "            loss = F.cross_entropy(logits, targets) #-loglikelihood\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens): #idx context : (1x8)\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx) # (1x8x90)\n",
    "            logits = logits[:,-1,:] # (1x90) eg \"HELLO\" -> nur \"O\" -> was komt danach?\n",
    "            probs = F.softmax(logits, dim = -1) #softmax läuft über letzte dimension -> C -> 90\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # -> (Bx1) eg (1x1) : prediction für jedes batch\n",
    "            idx = torch.cat((idx, idx_next), dim = 1) #neues ezichen an context (dim= 1) anhängen und von vorne\n",
    "        return idx # (B, T)\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e225247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Acht Blüpelunngech GAUnehan Sohtechlen Wek lin iest ger f dqun d ge\n",
      "Soge wewer (jem TIMEnse es hn GAROst mch ur\n",
      "Ise ndllaue!\n",
      "Sin\n",
      "Frtril West,\n",
      "Det HEPHE sih st Get srausch wafaß bem m.\n",
      "Hien,\n",
      "Dan zenne BRAYUSTOPHir, mk STOBündichr ickt g wich ichokandane b s Eh ie pfübeimen did, echen Eg fribrspr wer\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d5d587",
   "metadata": {},
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d14bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.352482557296753\n"
     ]
    }
   ],
   "source": [
    "#create pytorch optimizer\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr = 1e-3) #take gradients and updates paramters using gradients\n",
    "\n",
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    Xb, Yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = m(Xb, Yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "B,T, C = 4,8,2 \n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "xbow = torch.zeros((B,T,C)) # jeden wert überschreiben mit dem average dieses und der vorhergegangenen werte\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] #batch dimensio collapsed -> (T, C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0) # tensor befüllen it mean über T bis zu diesem (b,t) : (C)-Dimensional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0adce6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5278, -1.3105],\n",
       "        [ 0.3065,  0.0133],\n",
       "        [ 0.3509, -1.1684],\n",
       "        [-1.5037,  0.3656],\n",
       "        [-1.2367, -2.0583],\n",
       "        [ 0.0115, -0.7417],\n",
       "        [ 1.9602,  2.0247],\n",
       "        [-0.6529, -0.0203]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:] #batch dimensio collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dfa0e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5278, -1.3105],\n",
       "        [ 0.4171, -0.6486],\n",
       "        [ 0.3951, -0.8219],\n",
       "        [-0.0796, -0.5250],\n",
       "        [-0.3110, -0.8317],\n",
       "        [-0.2573, -0.8167],\n",
       "        [ 0.0595, -0.4108],\n",
       "        [-0.0295, -0.3619]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de963159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#math trick for calculating average with matmul\n",
    "a= torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a,1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27bfb368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[4., 2.],\n",
      "        [6., 4.],\n",
      "        [3., 6.]])\n",
      "tensor([[4.0000, 2.0000],\n",
      "        [5.0000, 3.0000],\n",
      "        [4.3333, 4.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97246d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "#2 version\n",
    "\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / torch.sum(wei, 1, keepdim=True) #(TxT)\n",
    "print(wei)\n",
    "xbow2 = wei @ x # (TxT) @ (BxTxC) -> broadcast: (BxTxT) @ (BxTxC) --> (BxTxC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6be96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 version with softmax - but same as before\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T)) #sozusagen gewichte für wie stark tokens von der past für aktuellen vonb beduetung sind -> aktuell alle gleich (avg)\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\")) # tokens der zukunft \n",
    "wei = F.softmax(wei, dim=1) #aggregation tru matmul\n",
    "wei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f855988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1955b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei # -> davon nehmen wir softmax: e**0 -> 1; e**-inf -> 0 : + wir teilen durch den durchschnitt aller exponierten zablen -> same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "152d6c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5278, -1.3105],\n",
       "        [ 0.3065,  0.0133],\n",
       "        [ 0.3509, -1.1684],\n",
       "        [-1.5037,  0.3656],\n",
       "        [-1.2367, -2.0583],\n",
       "        [ 0.0115, -0.7417],\n",
       "        [ 1.9602,  2.0247],\n",
       "        [-0.6529, -0.0203]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2478bae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53155181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self attention - important!!\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "#single head perform self attention:\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2,-1)\n",
    "\n",
    "#----\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "out = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a388ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9119, -0.7996,  0.2237,  0.3103, -0.6502,  0.7796, -0.2545,  1.0890,\n",
      "         -0.7220,  0.4920,  0.2178, -0.3586, -0.4156, -0.1003, -0.5914, -1.1405],\n",
      "        [ 0.0543,  0.7054,  0.1012, -0.5080,  0.6665, -0.3887, -0.2307, -0.2094,\n",
      "         -0.4271, -0.3596, -0.0501,  0.2800,  0.3002,  0.1591,  0.1481,  0.0156],\n",
      "        [ 0.6967,  0.3132,  0.7671, -1.0856,  0.6538,  0.0780,  0.8247, -0.3100,\n",
      "         -0.7909, -0.9614, -0.2006, -0.9673, -0.0624, -0.7161,  0.5843,  1.1758],\n",
      "        [-0.7319,  1.2356, -0.0898, -0.4766, -0.1670, -0.4727,  0.8346, -0.7599,\n",
      "          0.2044, -0.4377,  0.2654,  0.2589,  0.5989, -1.0341, -0.6693, -1.2190],\n",
      "        [-0.9374, -0.4238, -0.4296, -1.1212, -0.6118,  0.2220,  0.4336,  0.3282,\n",
      "          1.1225,  0.6090, -0.1138, -1.3528, -0.6403,  0.2924, -0.1331, -0.4245],\n",
      "        [ 0.1182,  0.1544, -0.5804, -0.3676, -0.0548, -0.3418,  1.2452, -0.6264,\n",
      "          0.6834, -0.6273,  1.1624,  0.8615, -0.3928,  1.4509,  0.8971,  0.2888],\n",
      "        [ 0.5002, -1.3573, -0.0448, -0.4300, -0.1068,  0.7683,  0.3837,  0.9848,\n",
      "         -0.1458, -0.6753, -0.3089,  0.1890, -0.5561,  0.1285,  0.1823,  0.6413],\n",
      "        [ 0.0758,  0.1753, -0.9296,  0.4774, -0.0375,  0.2556, -0.1145,  0.3820,\n",
      "         -0.4456, -0.4028, -0.2180,  0.1014, -0.5180,  1.3571,  0.1528, -0.0837]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.8468, -0.1356, -1.1608, -1.1490, -0.0168,  0.5181, -0.2838,  0.3179],\n",
      "        [-0.4285,  0.0153,  1.0496,  0.7427, -0.3360,  0.7371,  0.1856,  0.8131],\n",
      "        [ 0.2488, -0.1816,  0.9400, -0.2229,  0.7227,  0.6377,  0.4139, -0.2640],\n",
      "        [-0.0738,  0.3313,  0.6472,  1.1516, -1.0355,  0.3150,  0.0316,  0.2520],\n",
      "        [-0.1894, -0.1215,  0.0319, -0.8294,  0.9345, -0.3413,  0.1934, -0.6214],\n",
      "        [ 0.0294,  0.3990,  0.9323,  1.2593, -0.8763,  0.2659, -0.2320,  0.4638],\n",
      "        [ 0.2055,  0.1199, -0.6199, -0.0318,  0.3015, -0.3896, -0.3428, -0.3244],\n",
      "        [-0.1573,  0.2019, -0.4090,  0.4689, -0.2765,  0.3449,  0.5497,  0.9718],\n",
      "        [-0.5243,  1.1909,  0.2396,  0.1089, -0.0909, -0.6412, -0.3607, -0.7326],\n",
      "        [-0.1087, -0.2360,  1.4286,  0.0986, -0.3946, -0.0588,  0.9777,  0.1301],\n",
      "        [-1.1312,  0.1068,  0.0756, -0.6737,  0.4230, -0.0783, -0.0326, -1.1931],\n",
      "        [ 0.0414,  0.0710, -0.4032, -1.7203,  0.1322, -0.1794, -0.4305, -0.3361],\n",
      "        [ 0.1474, -0.3857, -0.0929, -0.8781,  0.2964, -0.6296,  0.2963, -0.2965],\n",
      "        [-0.0382, -0.2221, -0.1176,  0.3673, -0.4573,  0.3593,  0.2847,  0.2932],\n",
      "        [ 0.3376,  0.2749,  0.5425,  0.0122, -0.5959,  0.5431,  0.1963,  0.4015],\n",
      "        [-0.3028,  0.0473, -1.5373,  0.2046, -0.1262,  0.2833, -0.9085, -0.5401]],\n",
      "       grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(q[0])\n",
    "print(k[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22d576a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2964, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0853, 0.0328, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1076, 0.0328, 0.0027, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1219, 0.0817, 0.5840, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1450, 0.3358, 0.3770, 0.7971, 0.2381, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0216, 0.2698, 0.0053, 0.0020, 0.4435, 0.1282, 0.0000, 0.0000],\n",
       "        [0.1346, 0.1595, 0.0012, 0.0187, 0.2821, 0.2632, 0.1881, 0.0000],\n",
       "        [0.0875, 0.0875, 0.0298, 0.1773, 0.0363, 0.6087, 0.8119, 1.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6594da6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.9109e-02,  2.3587e-01, -3.8893e-01, -7.7123e-02, -2.7099e-01,\n",
       "         -1.1686e-01,  2.4445e-01, -3.7269e-01,  3.4395e-01,  7.8322e-02,\n",
       "          3.9790e-01, -3.5108e-04,  3.2620e-02, -1.6902e-01, -1.6058e-01,\n",
       "         -4.5493e-02,  3.2810e-01, -6.3747e-01,  3.9680e-01, -1.2584e-01,\n",
       "          2.9288e-01, -5.2683e-02, -1.0364e-01,  1.6027e-01, -6.5485e-02,\n",
       "         -1.1099e-02,  9.7853e-02, -7.6023e-02, -1.3767e-01,  1.2688e-01,\n",
       "         -5.0875e-02,  2.5266e-01],\n",
       "        [ 1.7104e-02,  4.4073e-02, -9.5218e-02, -5.0880e-02, -9.5342e-02,\n",
       "          2.4608e-03,  5.7961e-02, -9.5208e-02,  1.1083e-01,  1.0411e-02,\n",
       "          9.3894e-02,  1.3412e-02,  1.6317e-02, -5.5152e-02, -2.0997e-02,\n",
       "          1.0590e-02,  1.0021e-01, -1.5993e-01,  9.3288e-02, -2.5158e-02,\n",
       "          8.3073e-02,  9.2981e-03, -4.6963e-02,  8.8519e-02, -4.8803e-02,\n",
       "         -2.4674e-02,  2.3592e-03, -2.9304e-02, -2.1816e-02,  2.3253e-02,\n",
       "         -3.0828e-02,  1.1751e-01],\n",
       "        [ 1.5455e-02,  6.2410e-02, -1.2234e-01, -6.3203e-02, -1.1700e-01,\n",
       "         -3.3922e-03,  7.4406e-02, -1.2555e-01,  1.3804e-01,  1.2911e-02,\n",
       "          1.2253e-01,  1.2872e-02,  1.8939e-02, -7.3947e-02, -3.2606e-02,\n",
       "          1.0223e-02,  1.2218e-01, -2.0549e-01,  1.2516e-01, -4.0817e-02,\n",
       "          1.0232e-01,  1.0698e-02, -5.8387e-02,  1.0022e-01, -5.3662e-02,\n",
       "         -2.2001e-02,  7.3853e-03, -3.1334e-02, -3.3916e-02,  2.9880e-02,\n",
       "         -3.8368e-02,  1.3273e-01],\n",
       "        [ 3.2155e-01,  1.7364e-01,  3.2822e-01, -1.4798e+00, -4.2177e-01,\n",
       "          6.5665e-01, -3.3673e-01, -6.2417e-01,  4.5236e-01, -7.0547e-01,\n",
       "         -1.4179e-01, -7.6505e-02,  6.5665e-02, -1.3731e+00,  8.0525e-02,\n",
       "          6.7881e-01, -4.1365e-01,  2.7820e-01,  5.6667e-01, -1.3398e+00,\n",
       "         -4.8219e-01,  1.1722e+00, -8.5061e-01,  8.3169e-02, -8.1173e-02,\n",
       "          7.0083e-01, -5.2447e-01,  7.3220e-01, -3.9940e-01, -5.9866e-01,\n",
       "         -8.4461e-01, -5.9060e-01],\n",
       "        [ 7.3809e-01, -6.9502e-01,  1.6253e+00, -1.0702e+00, -3.1364e-02,\n",
       "          1.7700e+00, -1.2598e+00, -6.2685e-02, -5.9029e-01,  4.8966e-01,\n",
       "          7.5636e-01,  8.5053e-01,  1.4787e-01,  4.0254e-02, -3.2750e-01,\n",
       "          1.0691e+00,  1.4461e+00, -4.7367e-01,  1.9770e+00, -6.6305e-02,\n",
       "         -1.8372e+00,  1.5866e+00, -8.6042e-01,  4.9373e-01, -7.6589e-01,\n",
       "          1.3992e+00, -2.9102e+00, -5.7403e-02, -1.1236e+00, -1.4990e+00,\n",
       "         -7.8040e-01,  1.5302e+00],\n",
       "        [-3.0344e-01, -2.5173e-01,  1.4884e-01,  4.1921e-03, -3.2391e-01,\n",
       "          4.8230e-01, -7.7010e-01,  9.4830e-02, -5.4684e-01, -3.8518e-02,\n",
       "          6.9460e-02,  1.8102e-01, -1.8702e-02,  1.6350e-01,  1.6313e-01,\n",
       "          1.1130e+00,  5.8118e-01,  1.6348e-01,  2.1078e-02, -3.4488e-01,\n",
       "          1.3556e+00,  2.2367e-01, -8.5798e-01,  8.9877e-01, -2.5787e-01,\n",
       "         -1.7915e-02,  3.4495e-02, -4.8804e-01,  6.0066e-01, -2.7836e-01,\n",
       "         -3.6505e-01,  4.9823e-01],\n",
       "        [-4.8489e-01,  9.9802e-02, -6.6686e-02, -1.2381e-01, -4.9931e-01,\n",
       "          7.1538e-01, -1.9731e-01, -5.2747e-02, -4.8344e-01, -1.9977e-01,\n",
       "          3.9224e-01, -7.9680e-02,  3.6740e-01, -2.7726e-01,  2.2958e-01,\n",
       "          6.8707e-01,  5.0732e-01, -7.5803e-03,  2.1026e-01, -1.5236e-01,\n",
       "          1.1333e+00,  1.7896e-01, -5.1300e-01,  5.3517e-01, -3.1499e-01,\n",
       "          2.0448e-01,  1.2182e-01, -8.4147e-01,  4.3942e-01,  2.1130e-01,\n",
       "         -3.0331e-01, -1.2103e-01],\n",
       "        [ 2.4688e-01,  7.4617e-01,  9.5578e-01, -5.4312e-01, -9.1844e-01,\n",
       "          3.2186e+00,  6.8628e-02,  1.8141e+00, -1.0035e+00, -2.2845e+00,\n",
       "          1.2325e+00, -5.3403e-01,  3.0075e+00, -1.6480e+00,  1.4603e-01,\n",
       "         -1.8344e+00,  5.6763e-01, -3.9891e-01,  9.8648e-01,  2.9975e+00,\n",
       "          5.0456e-01,  7.8626e-01, -3.5346e-02, -1.3211e+00, -1.5386e+00,\n",
       "          2.1617e+00,  1.1854e+00, -1.2118e+00, -3.8607e-02,  7.1691e-01,\n",
       "         -2.3905e-01, -2.1545e+00]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(wei @ x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5188e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
